{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../X_train_new.pickle')\n",
    "X_test = pd.read_pickle('../X_test_new.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(inplace= True)\n",
    "X_test.dropna(inplace= True)\n",
    "X_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['tokenized_text'] = X_train['tokenized_text'].apply(lambda x: x.split())\n",
    "X_test['tokenized_text'] = X_test['tokenized_text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.sample(frac=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidf_no_token = TfidfVectorizer(tokenizer=identity_tokenizer, preprocessor=identity_tokenizer,token_pattern=None, max_features = 200, min_df = 10)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=identity_tokenizer,\n",
    "    preprocessor=identity_tokenizer,\n",
    "    token_pattern=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train['tokenized_text']\n",
    "x_test = X_test['tokenized_text']\n",
    "y_train = X_train['mental_state']\n",
    "y_test = X_test['mental_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_no_token.fit(x_train)\n",
    "fit_model = tfidf_no_token.transform(x_train)\n",
    "test_model = tfidf_no_token.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]CPU times: user 53min 21s, sys: 227 ms, total: 53min 21s\n",
      "Wall time: 53min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(probability=True, kernel='rbf', verbose = True)\n",
    "clf.fit(fit_model, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y_true, y_hat):\n",
    "    \n",
    "    y_true = list(map(lambda x: np.argmax(x), y_true))\n",
    "    y_hat = list(map(lambda x: np.argmax(x), y_hat))\n",
    "    \n",
    "    y_true_roc = pd.DataFrame(y_true, columns = ['mental_state'])\n",
    "    y_hat_roc = pd.DataFrame(y_hat, columns = ['mental_state'])\n",
    "    \n",
    "    y_true_roc = pd.get_dummies(y_true_roc['mental_state']).values\n",
    "    y_hat_roc = pd.get_dummies(y_hat_roc['mental_state']).values\n",
    "    \n",
    "    # result template\n",
    "    print('-'*40+' Result Report '+'-'*40)\n",
    "    \n",
    "    # Accuracy\n",
    "    print('Accuracy: ', accuracy_score(y_true,y_hat))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print('\\n')\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_true,y_hat))\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification Report\n",
    "    print('Classification Report: \\n')\n",
    "    print(classification_report(y_true, y_hat))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Aggregated area under the ROC curve\n",
    "    print('Area under ROC curve: ', roc_auc_score(y_true_roc, y_hat_roc, multi_class='ovo'))\n",
    "    \n",
    "    print('-'*95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test_model)\n",
    "y_target = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Result Report ----------------------------------------\n",
      "Accuracy:  0.7113909887290888\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 89233  15566   3163]\n",
      " [ 18121 129143  20861]\n",
      " [ 10620  37424  42299]]\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79    107962\n",
      "           1       0.71      0.77      0.74    168125\n",
      "           2       0.64      0.47      0.54     90343\n",
      "\n",
      "    accuracy                           0.71    366430\n",
      "   macro avg       0.70      0.69      0.69    366430\n",
      "weighted avg       0.71      0.71      0.70    366430\n",
      "\n",
      "\n",
      "\n",
      "Area under ROC curve:  0.7662392327095512\n",
      "-----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "performance(y_target, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mental_state(model, post, tokenizer):\n",
    "    \n",
    "    dic_state = {0:'Normal', 1:'Depressed', 2:'Suicidal'}\n",
    "    \n",
    "    SET_LIMIT_SENTENCE = 300\n",
    "    \n",
    "    print('Post: \\n')\n",
    "    print(post)\n",
    "    print('\\n')\n",
    "    \n",
    "    list_post = [post]\n",
    "    list_post_tokenized = tokenizer.transform(list_post)\n",
    "    \n",
    "    # classify mental state\n",
    "    mental_state = model.predict_proba(list_post_tokenized)\n",
    "    \n",
    "    print('Normal: ', str(round(mental_state[0][0], 2)*100)+'%')\n",
    "    print('Depressed: ', str(round(mental_state[0][1], 2)*100)+'%')\n",
    "    print('Suicidal: ', str(round(mental_state[0][2], 2)*100)+'%')\n",
    "    \n",
    "    classify_state = np.argmax(mental_state[0])\n",
    "    #list(map(lambda x: np.argmax(x), mental_state))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Model Classify: ', dic_state[classify_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post: \n",
      "\n",
      "['i', 'know', 'i', 'tried', 'everything', 'guys', 'i', 'gone', 'different', 'psychologists', 'types', 'anti', 'depressants', 'i', 'made', 'effort', 'get', 'bed', 'every', 'day', 'walk', 'my', 'dog', 'go', 'gym', 'read', 'distant', 'feeling', 'increases', 'exponentially', 'day', 'i', 'never', 'really', 'loved', 'life', 'i', 'loved', 'people', 'it', 'lately', 'spark', 'disappeared', 'i', 'connect', 'anyone', 'fine', 'i', 'even', 'connect', 'my', 'parents', 'kills', 'me', 'inside', 'i', 'want', 'stop', 'mundane', 'cycle', 'my', 'life', 'become', 'initially', 'i', 'told', 'myself', 'i', 'stick', 'it', 'them', 'i', 'longer', 'hold', 'restrictions', 'i', 'always', 'tried', 'my', 'best', 'persevere', 'keep', 'looking', 'forward', 'i', 'cried', 'day', 'today', 'i', 'realized', 'threshold', 'kept', 'me', 'taking', 'action', 'disappeared', 'i', 'want', 'it', 'feel', 'selfish', 'even', 'thoughts', 'somewhere', 'i', 'smiled', 'loved', 'i', 'feel', 'outcome', 'inevitable', 'please', 'help']\n",
      "\n",
      "\n",
      "Normal:  1.0%\n",
      "Depressed:  61.0%\n",
      "Suicidal:  39.0%\n",
      "\n",
      "\n",
      "Model Classify:  Depressed\n"
     ]
    }
   ],
   "source": [
    "post = X_test[X_test['mental_state']==2]['tokenized_text'][19]\n",
    "check_mental_state(clf, post, tfidf_no_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post: \n",
      "\n",
      "['cc', 'room', 'get', 'enough', 'love', 'time', 'day', 'come', 'play', 'some', 'music', 'hang', 'cc', 'room', 'great', 'way', 'find', 'new', 'music', 'chatting', 'lovely', 'people', 'we', 'got', 'people', 'room', 'we', 'would', 'love', 'come', 'party', 'us', 'follow', 'link', 'https', 'hit', 'headphones', 'sidebar', 'go', 'room', 'you', 'need', 'sign', 'you', 'account', 'already', 'it', 'quick', 'easy']\n",
      "\n",
      "\n",
      "Normal:  87.0%\n",
      "Depressed:  11.0%\n",
      "Suicidal:  2.0%\n",
      "\n",
      "\n",
      "Model Classify:  Normal\n"
     ]
    }
   ],
   "source": [
    "post = X_test[X_test['mental_state']==0]['tokenized_text'][2]\n",
    "check_mental_state(clf, post, tfidf_no_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post: \n",
      "\n",
      "['i', 'suicidal', 'thoughts', 'first', 'time', 'i', 'suicidal', 'thoughts', 'i', 'able', 'speak', 'my', 'problems', 'end', 'my', 'parents', 'finally', 'took', 'me', 'psychologist', 'they', 'always', 'said', 'i', 'lazy', 'lot', 'sad', 'things', 'happened', 'my', 'grandfather', 'passed', 'away', 'i', 'terribly', 'low', 'i', 'feeling', 'hopeful', 'barely', 'suicidal', 'thoughts', 'still', 'confidence', 'months', 'back', 'my', 'parents', 'started', 'arguing', 'lot', 'leading', 'divorce', 'my', 'mom', 'lied', 'much', 'got', 'me', 'stressed', 'point', 'i', 'ca', 'sleep', 'night', 'i', 'also', 'started', 'going', 'gym', 'improve', 'my', 'i', 'feel', 'tired', 'i', 'think', 'i', 'give', 'warning', 'might', 'trigger', 'i', 'tried', 'commit', 'suicide', 'times', 'never', 'told', 'my', 'parents', 'mostly', 'tried', 'hanging', 'myself', 'i', 'always', 'wanted', 'die', 'quickly', 'last', 'night', 'i', 'tried', 'cut', 'myself', 'never', 'thought', 'i', 'would', 'i', 'scared', 'i', 'might', 'myself', 'my', 'psychologist', 'vacation', 'i', 'feel', 'guilty', 'make', 'my', 'parents', 'waste', 'money', 'me', 'i', 'think', 'i', 'deserve', 'it', 'i', 'getting', 'distant', 'my', 'friends', 'i', 'want', 'hurt', 'them', 'i', 'kill', 'myself', 'i', 'trying', 'keep', 'my', 'mind', 'busy', 'arguing', 'making', 'me', 'stressed', 'every', 'day', 'it', 'seems', 'like', 'one', 'end', 'me', 'amp', 'amp']\n",
      "\n",
      "\n",
      "Normal:  0.0%\n",
      "Depressed:  3.0%\n",
      "Suicidal:  97.0%\n",
      "\n",
      "\n",
      "Model Classify:  Suicidal\n"
     ]
    }
   ],
   "source": [
    "post = X_test[X_test['mental_state']==1]['tokenized_text'][366423]\n",
    "check_mental_state(clf, post, tfidf_no_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>mental_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1193017</th>\n",
       "      <td>[fuck, everything, right, you, think, things, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646108</th>\n",
       "      <td>[i, i, dramatic, honestly, i, want, fucking, d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282304</th>\n",
       "      <td>[my, roommate, girlfriend, stole, my, fucking,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922522</th>\n",
       "      <td>[are, elderly, likely, watch, children, cartoo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083598</th>\n",
       "      <td>[my, friends, understand, much, i, want, leave...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784427</th>\n",
       "      <td>[falling, holes, depression, every, days, feel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135823</th>\n",
       "      <td>[marks, start, my, last, hour, alive, my, suic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427449</th>\n",
       "      <td>[anyone, else, scared, afterlife, we, punished...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668644</th>\n",
       "      <td>[i, got, vip, tickets, my, boyfriend, i, see, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424015</th>\n",
       "      <td>[know, anymore, i, depression, anxiety, issues...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43970 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tokenized_text  mental_state\n",
       "1193017  [fuck, everything, right, you, think, things, ...             1\n",
       "646108   [i, i, dramatic, honestly, i, want, fucking, d...             2\n",
       "282304   [my, roommate, girlfriend, stole, my, fucking,...             1\n",
       "922522   [are, elderly, likely, watch, children, cartoo...             0\n",
       "1083598  [my, friends, understand, much, i, want, leave...             2\n",
       "...                                                    ...           ...\n",
       "784427   [falling, holes, depression, every, days, feel...             1\n",
       "1135823  [marks, start, my, last, hour, alive, my, suic...             2\n",
       "1427449  [anyone, else, scared, afterlife, we, punished...             2\n",
       "668644   [i, got, vip, tickets, my, boyfriend, i, see, ...             0\n",
       "424015   [know, anymore, i, depression, anxiety, issues...             1\n",
       "\n",
       "[43970 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
